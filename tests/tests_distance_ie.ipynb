{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "# local\n",
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.insert(0, '..')\n",
    "\n",
    "from datasets.import_dataset import import_dataset\n",
    "from trainer import Trainer\n",
    "import clamiter as ci\n",
    "from transformation import RealNVP, train_prior, get_cov\n",
    "from utils.plotting import *\n",
    "import datasets.simulations as sim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'device = {device}')\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exotic Shapes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Pseudo Metric Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#* NEXT ARE DIFFERENT DEFINITIONS FOR 2 COMMUNITY GRAPHS\n",
    "num_samples = 1000\n",
    "\n",
    "# SHAPES FROM NF CLASS\n",
    "# todo: import dataset \n",
    "#* two moons\n",
    "graph_two_moons, dist_two_moons = sim.sample_normflows_dist(num_samples, 'TwoMoons', lorenz=True)\n",
    "\n",
    "# #* circular gaussian mixture\n",
    "graph_circ_gaus, dist_circ_gaus = sim.sample_normflows_dist(num_samples, 'Circ', lorenz=True)\n",
    "\n",
    "\n",
    "\n",
    "_, axes_moons = plt.subplots(1, 2, figsize=(6, 3))\n",
    "plot_2dgraph(graph_two_moons, lorenz_fig_lims=True, ax=axes_moons[0])\n",
    "# plot_normflows_dist(dist_two_moons,shift=-0.5, scale=5, device=device, x_fig_lim=[-0.1, 1.1], ax=axes_moons[0])\n",
    "plot_normflows_dist(dist_two_moons, lorenz=True, x_fig_lim=[0, 2.7], y_fig_lim=[-1.7,1.7], ax=axes_moons[1])\n",
    "\n",
    "_, axes_circ = plt.subplots(1, 2, figsize=(6, 3))\n",
    "plot_2dgraph(graph_circ_gaus, lorenz_fig_lims=True, ax=axes_circ[0])\n",
    "# plot_normflows_dist(dist_circ_gaus,shift=-0.5, scale=5, device=device, x_fig_lim=[-0.1, 1.1], ax=axes_circ[0])\n",
    "plot_normflows_dist(dist_circ_gaus,lorenz=True, x_fig_lim=[0, 2.7],y_fig_lim=[-1.7,1.7], ax=axes_circ[1])\n",
    "#TODO: plot_normflow_dist needs to plot lorenz or not lorenz!!!!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# _, axes_chubs = plt.subplots(1, 2, figsize=(6, 3))\n",
    "# plot_2dgraph(graph_two_chubs, lorenz_fig_lims=False, x_fig_lim=[-0.1, 1.1], ax=axes_chubs[0])\n",
    "# plot_normflows_dist(dist_two_chubs,shift=-0.5, scale=5, device=device, x_fig_lim=[-0.1, 1.1], ax=axes_chubs[0])\n",
    "# plot_normflows_dist(dist_two_chubs,shift=-0.5, scale=5, device=device, x_fig_lim=[-0.1, 1.1], ax=axes_chubs[1])\n",
    "\n",
    "\n",
    "#todo: make sure that the distance runs. then put in a different folder and rearange\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IECLAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_iegam_twomoons = Trainer(\n",
    "                model_name='iegam',\n",
    "                task=None,\n",
    "                device=device,\n",
    "                dataset=graph_two_moons.clone()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i want to optimize the trainer\n",
    "losses_moons_ieclam, test_acc_moons_ieclam, val_acc_moons_ieclam = trainer_iegam_twomoons.train(\n",
    "    init_feats=True,\n",
    "    init_type='small_gaus',\n",
    "    plot_every=-1,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PieClam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two Moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_triplets = [\n",
    "                    ['feat_opt', 'n_iter', 2000],\n",
    "                    ['feat_opt', 'lr', 0.00005],\n",
    "                    ['prior_opt', 'n_iter', 1500],\n",
    "                    ['prior_opt', 'lr', 0.0000005],\n",
    "                    ['prior_opt', 'noise_amp', 0.1],\n",
    "                    ['back_forth','n_back_forth', 50],\n",
    "                    ['back_forth', 'first_func_in_fit', 'feat_opt']\n",
    "                ]\n",
    "\n",
    "\n",
    "\n",
    "trainer_pieclam_twomoons = Trainer(\n",
    "                model_name='piegam',\n",
    "                task=None,\n",
    "                device=device,\n",
    "                config_triplets_to_change=config_triplets,\n",
    "                dataset=graph_two_moons.clone()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i want to optimize the trainer\n",
    "losses_pieclam_moons, test_acc_moons, val_acc_moons = trainer_pieclam_twomoons.train(\n",
    "    task_params={'d' : 0.2},\n",
    "    plot_every=-1,\n",
    "    init_feats=True,\n",
    "    init_type='small_gaus',\n",
    "    verbose=False,\n",
    "    verbose_in_funcs=False\n",
    ")\n",
    "#todo: need to make default values for optimization and that the individual configurations be only some of the values...\n",
    "\n",
    "# make default optimization values. use the mighty config and the individual configs should be config triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(get_prob_graph(trainer_bigclam_distance_twomoons.data.x, lorenz=False).cpu().flatten(), linestyle=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axes[0].plot(losses_moons)\n",
    "axes[0].set_title('loss')\n",
    "axes[1].plot(logcut_moons)\n",
    "axes[1].set_title('log cut')\n",
    "axes[2].plot(l2_moons)\n",
    "axes[2].set_title('l2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#todo: make optimization for d that provides the minimum for log cut without the d\n",
    "\n",
    "#todo: add the option to measure with sbm in train function add an attribute in the data object of the sbm that is the edge attr for the sbm\n",
    "#First\n",
    "# todo: recreate priors with pclam\n",
    "# todo: make graphs in timecone and recreate with pieclam\n",
    "\n",
    "# sbm\n",
    "# todo: sbm and measure log cut in train. add also cut distance to test accuracy\n",
    "# todo: the two other sbms ron suggested\n",
    "# todo: 2,3,4 communities in pclam for the sbm and see that 2 is the best\n",
    "# todo: 2,4 communities in pieclam for the sbm and show that 4 is the best \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_triplets = [\n",
    "#                     ['feat_opt', 'n_iter', 2000],\n",
    "#                     ['feat_opt', 'lr', 0.00005],\n",
    "#                     ['prior_opt', 'n_iter', 1500],\n",
    "#                     ['prior_opt', 'lr', 0.0000005],\n",
    "#                     ['prior_opt', 'noise_amp', 0.25],\n",
    "#                     ['back_forth','n_back_forth', 50],\n",
    "#                     ['back_forth', 'first_func_in_fit', 'feat_opt']\n",
    "                ]\n",
    "\n",
    "\n",
    "\n",
    "trainer_iegam_circ = Trainer(\n",
    "                model_name='iegam',\n",
    "                task=None,\n",
    "                device=device,\n",
    "                config_triplets_to_change=config_triplets,\n",
    "                dataset=graph_circ_gaus.clone()\n",
    ")\n",
    "\n",
    "losses_iegam_circ, acc_test_iegam_circ, acc_val_iegam_circ = trainer_iegam_circ.train(\n",
    "    task_params={'d' : 0.2},\n",
    "    plot_every=-1,\n",
    "    init_feats=True,\n",
    "    init_type='small_gaus',\n",
    "    verbose=False,\n",
    "    verbose_in_funcs=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIRC\n",
    "config_triplets = [\n",
    "                    ['feat_opt', 'n_iter', 2000],\n",
    "                    ['feat_opt', 'lr', 0.00005],\n",
    "                    ['prior_opt', 'n_iter', 1500],\n",
    "                    ['prior_opt', 'lr', 0.0000005],\n",
    "                    ['prior_opt', 'noise_amp', 0.1],\n",
    "                    ['back_forth','n_back_forth', 50],\n",
    "                    ['back_forth', 'first_func_in_fit', 'feat_opt']\n",
    "                ]\n",
    "\n",
    "\n",
    "\n",
    "trainer_piegam_circ = Trainer(\n",
    "                model_name='piegam',\n",
    "                task=None,\n",
    "                device=device,\n",
    "                config_triplets_to_change=config_triplets,\n",
    "                dataset=graph_circ_gaus.clone()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i want to optimize the trainer\n",
    "losses_piegam_circ, acc_test_piegam_circ, acc_val_piegam_circ = trainer_piegam_circ.train(\n",
    "    task_params={'d' : 0.2},\n",
    "    plot_every=5,\n",
    "    init_feats=True,\n",
    "    init_type='small_gaus',\n",
    "    verbose=False,\n",
    "    verbose_in_funcs=False\n",
    ")\n",
    "#todo: need to make default values for optimization and that the individual configurations be only some of the values...\n",
    "\n",
    "# make default optimization values. use the mighty config and the individual configs should be config triplets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
