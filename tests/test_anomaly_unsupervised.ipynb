{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# load the model from the file \"sbm3x3_pclam_roc_0.210_auc_0.860\"\n",
    "import torch\n",
    "from torch_geometric.transforms import TwoHop\n",
    "\n",
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.insert(0, '..')\n",
    "\n",
    "from datasets.import_dataset import import_dataset\n",
    "from utils.plotting import *\n",
    "from trainer import Trainer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using device:', device)\n",
    "cpu = torch.device(\"cpu\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "/home/user/Documents/danny/AAAI_pieclam/tests/../trainer.py:415:::  \n",
      " starting optimization of piegam on ellipticGGAD on device cuda\n",
      "\n",
      " configs_dict: \n",
      "{\n",
      "    \"clamiter_init\": {\n",
      "        \"dim_feat\": 30,\n",
      "        \"dim_attr\": 93,\n",
      "        \"s_reg\": 0.0,\n",
      "        \"l1_reg\": 1,\n",
      "        \"T\": 1,\n",
      "        \"hidden_dim\": 64,\n",
      "        \"num_coupling_blocks\": 32,\n",
      "        \"num_layers_mlp\": 2\n",
      "    },\n",
      "    \"feat_opt\": {\n",
      "        \"lr\": 3e-06,\n",
      "        \"n_iter\": 500,\n",
      "        \"early_stop\": 0\n",
      "    },\n",
      "    \"prior_opt\": {\n",
      "        \"n_iter\": 1300,\n",
      "        \"lr\": 2e-06,\n",
      "        \"noise_amp\": 0.05,\n",
      "        \"weight_decay\": 0.1,\n",
      "        \"early_stop\": 0\n",
      "    },\n",
      "    \"back_forth\": {\n",
      "        \"n_back_forth\": 5,\n",
      "        \"scheduler_step_size\": 1,\n",
      "        \"scheduler_gamma\": 0.5,\n",
      "        \"early_stop_fit\": 0,\n",
      "        \"first_func_in_fit\": \"fit_feats\"\n",
      "    }\n",
      "}\n",
      "\n",
      "\n",
      "/home/user/Documents/danny/AAAI_pieclam/tests/../trainer.py:420:::  \n",
      " train_model_on_params, initializing feats with small_gaus\n",
      "\n",
      "\n",
      "/home/user/Documents/danny/AAAI_pieclam/tests/../trainer.py:428:::  \n",
      " init_node_feats took 0.0033257007598876953 seconds\n",
      "\n",
      "\n",
      "/home/user/Documents/danny/AAAI_pieclam/tests/../clamiter.py:499:::  \n",
      "fit, task='anomaly'\n",
      "\n",
      "\n",
      "/home/user/Documents/danny/AAAI_pieclam/tests/../clamiter.py:542:::  \n",
      "in fit,\n",
      "first_func_in_fit='fit_feats'\n",
      "second_function_name='fit_prior'\n",
      "\n",
      "\n",
      "/home/user/Documents/danny/AAAI_pieclam/tests/../clamiter.py:600:::  \n",
      "back and forth 1/5\n",
      "\n",
      "\n",
      "/home/user/Documents/danny/AAAI_pieclam/tests/../clamiter.py:643:::  \n",
      "fit, back and forth 1/5 took 99.66231346130371 seconds\n",
      "ANOMALY TEST accuracy.\n",
      "Latest:\n",
      "vanilla_star: 0.4364785647192043 prior: 0.6209977384041333 prior_star: 0.44777085936420163 \n",
      "Best:\n",
      "vanilla_star: 0.49356444817674683 at iteration 19\n",
      "prior: 0.6209977384041333 at iteration 1799\n",
      "prior_star: 0.49227273105238 at iteration 19\n",
      "\n",
      "\n",
      "/home/user/Documents/danny/AAAI_pieclam/tests/../utils/utils.py:746:::  \n",
      "scheduler made step. changes:\n",
      "feats lr: 3e-06 to 1.5e-06\n",
      "feats n_iter changed from 500 to 500\n",
      "noise_amp from 0.05 to 0.025\n",
      "prior lr from 2e-06 to 1e-06\n",
      "\n",
      "\n",
      "/home/user/Documents/danny/AAAI_pieclam/tests/../clamiter.py:600:::  \n",
      "back and forth 2/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 47\u001b[0m\n\u001b[1;32m     21\u001b[0m config_triplets \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     22\u001b[0m     [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclamiter_init\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdim_feat\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m30\u001b[39m],\n\u001b[1;32m     23\u001b[0m     [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclamiter_init\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdim_attr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m100\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mback_forth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_func_in_fit\u001b[39m\u001b[38;5;124m'\u001b[39m, first_func]\n\u001b[1;32m     33\u001b[0m ]\n\u001b[1;32m     37\u001b[0m trainer_anomaly \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     38\u001b[0m     model_name\u001b[38;5;241m=\u001b[39mmodel_name,\n\u001b[1;32m     39\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     config_triplets_to_change\u001b[38;5;241m=\u001b[39mconfig_triplets\n\u001b[1;32m     45\u001b[0m )\n\u001b[0;32m---> 47\u001b[0m losses, acc_test, acc_val \u001b[38;5;241m=\u001b[39m trainer_anomaly\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[1;32m     48\u001b[0m     init_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmall_gaus\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     49\u001b[0m     init_feats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     50\u001b[0m     acc_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m     51\u001b[0m     plot_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     52\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     53\u001b[0m     verbose_in_funcs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     54\u001b[0m )\n\u001b[1;32m     55\u001b[0m losseses\u001b[38;5;241m.\u001b[39mappend(losses)\n\u001b[1;32m     56\u001b[0m acc_testses\u001b[38;5;241m.\u001b[39mappend(acc_test)\n",
      "File \u001b[0;32m~/Documents/danny/AAAI_pieclam/tests/../trainer.py:483\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, init_type, dyads_to_omit, task_params, init_feats, acc_every, performance_metric, prior_fit_mask, plot_every, verbose, verbose_in_funcs, node_feats_for_init)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mStepLR(\n\u001b[1;32m    470\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, \n\u001b[1;32m    471\u001b[0m             step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfigs_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mback_forth\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscheduler_step_size\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m    472\u001b[0m             gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfigs_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mback_forth\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscheduler_gamma\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    474\u001b[0m fit_opt_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeat_params\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfigs_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeat_opt\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    476\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprior_params\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfigs_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprior_opt\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mearly_stop_fit\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfigs_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mback_forth\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mearly_stop_fit\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    481\u001b[0m         }\n\u001b[0;32m--> 483\u001b[0m losses, accuracies_test, accuracies_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclamiter\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m    484\u001b[0m                         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, \n\u001b[1;32m    485\u001b[0m                         optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler,\n\u001b[1;32m    486\u001b[0m                         dyads_to_omit\u001b[38;5;241m=\u001b[39mdyads_to_omit, \n\u001b[1;32m    487\u001b[0m                         prior_fit_mask\u001b[38;5;241m=\u001b[39mprior_fit_mask,\n\u001b[1;32m    488\u001b[0m \n\u001b[1;32m    489\u001b[0m                         task\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask, \n\u001b[1;32m    490\u001b[0m                         acc_every\u001b[38;5;241m=\u001b[39macc_every, \n\u001b[1;32m    491\u001b[0m                         performance_metric\u001b[38;5;241m=\u001b[39mperformance_metric,\n\u001b[1;32m    492\u001b[0m                         configs_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfigs_dict,\n\u001b[1;32m    493\u001b[0m \n\u001b[1;32m    494\u001b[0m                         plot_final_res\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    495\u001b[0m                         plot_every\u001b[38;5;241m=\u001b[39mplot_every,\n\u001b[1;32m    496\u001b[0m                         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    497\u001b[0m                         verbose_in_funcs\u001b[38;5;241m=\u001b[39mverbose_in_funcs,\n\u001b[1;32m    498\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_opt_params)\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m    502\u001b[0m     printd(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtrain_model_on_params on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtook \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mt_train_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/danny/AAAI_pieclam/tests/../clamiter.py:606\u001b[0m, in \u001b[0;36mPCLAMIter.fit\u001b[0;34m(self, graph, first_func_in_fit, optimizer, scheduler, n_back_forth, dyads_to_omit, prior_fit_mask, plot_every, acc_every, early_stop_fit, early_stops, performance_metric, configs_dict, task, verbose_in_funcs, verbose, **params)\u001b[0m\n\u001b[1;32m    604\u001b[0m t_first \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 606\u001b[0m     losses_epoch_1st, accuracies_test_epoch_1st, accuracies_val_epoch_1st \u001b[38;5;241m=\u001b[39m first_func()\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    608\u001b[0m     printd(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mfit func. nerror in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfirst_func_in_fit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at iter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/danny/AAAI_pieclam/tests/../clamiter.py:520\u001b[0m, in \u001b[0;36mPCLAMIter.fit.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    516\u001b[0m     prior_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mearly_stop\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m early_stops[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    517\u001b[0m     feat_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mearly_stop\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m early_stops[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 520\u001b[0m fit_feats_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_feats(\n\u001b[1;32m    521\u001b[0m                     graph, \n\u001b[1;32m    522\u001b[0m                     dyads_to_omit\u001b[38;5;241m=\u001b[39mdyads_to_omit, \n\u001b[1;32m    523\u001b[0m                     verbose\u001b[38;5;241m=\u001b[39mverbose_in_funcs,\n\u001b[1;32m    524\u001b[0m                     task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[1;32m    525\u001b[0m                     acc_every\u001b[38;5;241m=\u001b[39macc_every,\n\u001b[1;32m    526\u001b[0m                     performance_metric\u001b[38;5;241m=\u001b[39mperformance_metric,\n\u001b[1;32m    527\u001b[0m                     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfeat_params)\n\u001b[1;32m    529\u001b[0m fit_prior_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_prior(\n\u001b[1;32m    530\u001b[0m                     graph\u001b[38;5;241m=\u001b[39mgraph, \n\u001b[1;32m    531\u001b[0m                     node_mask\u001b[38;5;241m=\u001b[39mprior_fit_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    536\u001b[0m                     verbose\u001b[38;5;241m=\u001b[39mverbose_in_funcs, \n\u001b[1;32m    537\u001b[0m                     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprior_params)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;66;03m# FIRST AND SECOND PARAMS\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/danny/AAAI_pieclam/tests/../clamiter.py:416\u001b[0m, in \u001b[0;36mPCLAMIter.fit_feats\u001b[0;34m(self, graph, n_iter, lr, task, node_mask, performance_metric, dyads_to_omit, early_stop, cutoff, verbose, acc_every, plot_every)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_feats\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m    399\u001b[0m               graph, \n\u001b[1;32m    400\u001b[0m               n_iter, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    410\u001b[0m               plot_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100000\u001b[39m,\n\u001b[1;32m    411\u001b[0m               ):\n\u001b[1;32m    413\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''optimize the features using iterations of clamiter.\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;124;03m    param: node_mask: a mask for the nodes to optimize, the rest should stay unchanged'''\u001b[39;00m\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_wrapper(graph\u001b[38;5;241m=\u001b[39mgraph,\n\u001b[1;32m    417\u001b[0m                             n_iter\u001b[38;5;241m=\u001b[39mn_iter, \n\u001b[1;32m    418\u001b[0m                             lr\u001b[38;5;241m=\u001b[39mlr, \n\u001b[1;32m    419\u001b[0m                             task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[1;32m    420\u001b[0m                             which_fit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit_feats\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    421\u001b[0m                             node_mask\u001b[38;5;241m=\u001b[39mnode_mask,\n\u001b[1;32m    422\u001b[0m                             performance_metric\u001b[38;5;241m=\u001b[39mperformance_metric,\n\u001b[1;32m    423\u001b[0m                             dyads_to_omit\u001b[38;5;241m=\u001b[39mdyads_to_omit, \n\u001b[1;32m    424\u001b[0m                             early_stop\u001b[38;5;241m=\u001b[39mearly_stop,\n\u001b[1;32m    425\u001b[0m                             cutoff\u001b[38;5;241m=\u001b[39mcutoff, \n\u001b[1;32m    426\u001b[0m                             verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    427\u001b[0m                             acc_every\u001b[38;5;241m=\u001b[39macc_every, \n\u001b[1;32m    428\u001b[0m                             plot_every\u001b[38;5;241m=\u001b[39mplot_every\n\u001b[1;32m    429\u001b[0m                             )\n",
      "File \u001b[0;32m~/Documents/danny/AAAI_pieclam/tests/../clamiter.py:353\u001b[0m, in \u001b[0;36mPCLAMIter.fit_wrapper\u001b[0;34m(self, graph, n_iter, lr, task, which_fit, early_stop, cutoff, verbose, acc_every, plot_every, **kwargs)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iter):\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m         loss \u001b[38;5;241m=\u001b[39m iter_step()\n\u001b[1;32m    354\u001b[0m         losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/danny/AAAI_pieclam/tests/../clamiter.py:275\u001b[0m, in \u001b[0;36mPCLAMIter.fit_wrapper.<locals>.iter_step_feat\u001b[0;34m()\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miter_step_feat\u001b[39m():\n\u001b[0;32m--> 275\u001b[0m     clamiter_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(graph, node_mask)\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug_last_grad \u001b[38;5;241m=\u001b[39m clamiter_grad\n\u001b[1;32m    277\u001b[0m     graph\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeat_bounding(graph\u001b[38;5;241m.\u001b[39mx, clamiter_grad, lr, node_mask, cutoff), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5000\u001b[39m,\u001b[38;5;241m5000\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/piegam/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/piegam/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/danny/AAAI_pieclam/tests/../clamiter.py:154\u001b[0m, in \u001b[0;36mPCLAMIter.forward\u001b[0;34m(self, graph, node_mask)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m#? for omittion calc the prior, omit the nodes, add all up, looks good\u001b[39;00m\n\u001b[1;32m    152\u001b[0m log_prior_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprior\u001b[38;5;241m.\u001b[39mforward_ll(feats_for_prior)\n\u001b[0;32m--> 154\u001b[0m masked_prior_grad \u001b[38;5;241m=\u001b[39m a_grad(log_prior_loss, feats_for_prior, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    155\u001b[0m prior_grad[node_mask] \u001b[38;5;241m=\u001b[39m masked_prior_grad[:, :\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim_feat]\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m#the extra clone means the data of the tensor is different. tested, it doesn't take longer.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/piegam/lib/python3.11/site-packages/torch/autograd/__init__.py:411\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    407\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    408\u001b[0m         grad_outputs_\n\u001b[1;32m    409\u001b[0m     )\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 411\u001b[0m     result \u001b[38;5;241m=\u001b[39m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    412\u001b[0m         t_outputs,\n\u001b[1;32m    413\u001b[0m         grad_outputs_,\n\u001b[1;32m    414\u001b[0m         retain_graph,\n\u001b[1;32m    415\u001b[0m         create_graph,\n\u001b[1;32m    416\u001b[0m         inputs,\n\u001b[1;32m    417\u001b[0m         allow_unused,\n\u001b[1;32m    418\u001b[0m         accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    419\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    422\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[1;32m    424\u001b[0m     ):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model_names = ['iegam','piegam', 'bigclam', 'pclam']\n",
    "ds_names = ['ellipticGGAD', 'redditGGAD', 'photoGGAD']\n",
    "#! problem with something to do with attr with reddit and elliptic\n",
    "for ds_name in ds_names:    \n",
    "    ds = import_dataset(ds_name)\n",
    "    fat_ds = TwoHop()(ds)\n",
    "    fat_ds.edge_attr = torch.ones(fat_ds.edge_index.shape[1]).bool()\n",
    "\n",
    "    if ds_name in ['Flickr', 'ACM', 'BlogCatalog']:\n",
    "        ds_to_use = ds\n",
    "    elif ds_name in ['redditGGAD', 'photoGGAD', 'ellipticGGAD']:\n",
    "        ds_to_use = fat_ds\n",
    "    else:\n",
    "        raise ValueError('ds_name not recognized')\n",
    "\n",
    "\n",
    "    losseses = []\n",
    "    acc_testses = []\n",
    "    acc_valses = []\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        config_triplets = [\n",
    "            ['clamiter_init', 'dim_feat', 30],\n",
    "            ['clamiter_init', 'dim_attr', 100],\n",
    "            # ['feat_opt','n_iter', 100],\n",
    "            # ['prior_opt', 'n_iter', 200],\n",
    "            ['feat_opt', 'lr', 3e-6],\n",
    "            ['prior_opt', 'lr', 2e-6],\n",
    "            ['prior_opt', 'noise_amp', 0.05],\n",
    "            ['back_forth', 'n_back_forth', 5],\n",
    "            ['back_forth', 'scheduler_step_size', 1],\n",
    "            ['back_forth', 'scheduler_gamma', 0.5],\n",
    "            ['back_forth', 'first_func_in_fit', first_func]\n",
    "        ]\n",
    "\n",
    "\n",
    "\n",
    "        trainer_anomaly = Trainer(\n",
    "            model_name=model_name,\n",
    "            device=device,\n",
    "            dataset=ds_to_use.clone(),\n",
    "            attr_opt=True,\n",
    "            task='anomaly',\n",
    "            mighty_configs_dict=True,\n",
    "            config_triplets_to_change=config_triplets\n",
    "        )\n",
    "\n",
    "        losses, acc_test, acc_val = trainer_anomaly.train(\n",
    "            init_type='small_gaus',\n",
    "            init_feats=True,\n",
    "            acc_every=20,\n",
    "            plot_every=-1,\n",
    "            verbose=True,\n",
    "            verbose_in_funcs=False\n",
    "        )\n",
    "        losseses.append(losses)\n",
    "        acc_testses.append(acc_test)\n",
    "        acc_valses.append(acc_val)\n",
    "\n",
    "del ds, fat_ds\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "piegam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
