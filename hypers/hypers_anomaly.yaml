       
# 88""Yb 888888 8888b.  8888b.  88 888888 
# 88__dP 88__    8I  Yb  8I  Yb 88   88   
# 88"Yb  88""    8I  dY  8I  dY 88   88   
# 88  Yb 888888 8888Y"  8888Y"  88   88   

redditGGAD_bigclam:
    clamiter_init:
        dim_feat: 18
        dim_attr: 64
        s_reg: 0.0
        l1_reg: 1
        T: 1
    feat_opt:
        lr: 0.000001
        n_iter: 1700

redditGGAD_iegam:
    clamiter_init:
        dim_feat: 24
        dim_attr: 40
        s_reg: 0.0
        l1_reg: 1
        T: 1
    feat_opt:
        lr: 0.000001
        n_iter: 2000
        

redditGGAD_pclam:
    clamiter_init:
        dim_feat: 18
        dim_attr: 40
        s_reg: 0.0
        l1_reg: 1
        T: 1
        hidden_dim: 64
        num_coupling_blocks: 32 
        num_layers_mlp: 2
    prior_opt:
        n_iter: 10000
        lr: 0.0001
        noise_amp: 0.005
        weight_decay: 0.1
        
    back_forth:
        n_back_forth: 20
        scheduler_step_size: 1
        scheduler_gamma: 0.5
        first_func_in_fit: 'fit_prior'

# redditGGAD_piegam:
#     clamiter_init:
#         dim_feat: 24
#         dim_attr: 64
#         s_reg: 0.0
#         l1_reg: 1
#         T: 1
#         hidden_dim: 64
#         num_coupling_blocks: 32 
#         num_layers_mlp: 2
#     prior_opt:
#         n_iter: 10000
#         lr: 0.0001
#         noise_amp: 0.005
#         weight_decay: 0.1
        
#     back_forth:
#         n_back_forth: 30
#         scheduler_step_size: 1
#         scheduler_gamma: 0.5
#         first_func_in_fit: 'fit_prior'

        


# 888888 88     88     88 88""Yb 888888 88  dP""b8 
# 88__   88     88     88 88__dP   88   88 dP   `" 
# 88""   88  .o 88  .o 88 88"""    88   88 Yb      
# 888888 88ood8 88ood8 88 88       88   88  YboodP 

ellipticGGAD_bigclam:
    clamiter_init:
        dim_feat: 18
        dim_attr: 32
        s_reg: 0.0
        l1_reg: 1
        T: 1
    feat_opt:
        lr: 0.000001
        n_iter: 20000
        

ellipticGGAD_iegam:
    clamiter_init:
        dim_feat: 24
        dim_attr: 32
        s_reg: 0.0
        l1_reg: 1
        T: 1
    feat_opt:
        lr: 0.000001
        n_iter: 50000
       

ellipticGGAD_pclam:
    clamiter_init:
        dim_feat: 25
        dim_attr: 100
        s_reg: 0.0
        l1_reg: 1
        T: 1
        hidden_dim: 64
        num_coupling_blocks: 32 
        num_layers_mlp: 2
    feat_opt:
        lr: 0.00001
        n_iter: 100
       
    prior_opt:
        lr: 0.00001
        n_iter: 1000
        noise_amp: 0.05
        weight_decay: 0.1
       
    back_forth:
        n_back_forth: 20
        scheduler_step_size: 1
        scheduler_gamma: 0.5
        first_func_in_fit: 'fit_prior'
       

ellipticGGAD_piegam:
# the configuration is the same as the global


# 88""Yb 88  88  dP"Yb  888888  dP"Yb  
# 88__dP 88  88 dP   Yb   88   dP   Yb 
# 88"""  888888 Yb   dP   88   Yb   dP 
# 88     88  88  YbodP    88    YbodP  

photoGGAD_bigclam:
    clamiter_init:
        dim_feat: 30
        dim_attr: 500
        s_reg: 0.0
        l1_reg: 1
        T: 1
    feat_opt:
        lr: 0.000001
        n_iter: 20000
        

photoGGAD_iegam:
    clamiter_init:
        dim_feat: 30
        dim_attr: 500
        s_reg: 0.0
        l1_reg: 1
        T: 1
    feat_opt:
        lr: 0.000001
        n_iter: 20000
        

photoGGAD_pclam:
    clamiter_init:
        dim_feat: 20
        dim_attr: 100
        s_reg: 0.0
        l1_reg: 1
        T: 1
        hidden_dim: 64
        num_coupling_blocks: 32 
        num_layers_mlp: 2
    feat_opt:
        lr: 0.00001
        n_iter: 100
        
    prior_opt:
        lr: 0.00001
        n_iter: 1000
        noise_amp: 0.05
        weight_decay: 0.1
        
    back_forth:
        n_back_forth: 100
        scheduler_step_size: 1
        scheduler_gamma: 0.5
        first_func_in_fit: 'fit_prior'
        

# photoGGAD_piegam:
#     clamiter_init:
#        s_reg : 0.0
#     feat_opt:
#         lr: 0.00001
#         n_iter: 500
#     prior_opt:
#         lr: 0.00001
#         n_iter: 1000
#         noise_amp: 0.05
#         weight_decay: 0.1
        
#     back_forth:
#         n_back_forth: 100
#         scheduler_step_size: 1
#         scheduler_gamma: 0.5
#         first_func_in_fit: 'fit_prior'


# interesting values:
# 0.01, 32, 32, 2: give more iterations in the second classify anomaly. seems to not saturate. seems that way also after many tries! not so sure that that is true. for 0.5 i think that 3 layer mlp might have been better
# what happens when the loss climbs really high? is it good for anomaly detection? 
# these numbers are the first time i went over the base in 0.2! and maybe can still be made better!


#  dP""b8 88      dP"Yb  88""Yb    db    88     
# dP   `" 88     dP   Yb 88__dP   dPYb   88     
# Yb  "88 88  .o Yb   dP 88""Yb  dP__Yb  88  .o 
#  YboodP 88ood8  YbodP  88oodP dP""""Yb 88ood8 


MightyConfigs_iegam:
    clamiter_init: 
        dim_feat: 30
        dim_attr: 64
        s_reg: 0.0
        l1_reg: 1
        T: 1
        hidden_dim: 64
        num_coupling_blocks: 32
        num_layers_mlp: 2
    feat_opt: 
        lr: 0.000001
        n_iter: 2000
        early_stop: 0
    

MightyConfigs_piegam:
    clamiter_init: 
        dim_feat: 30
        dim_attr: 100
        s_reg: 0.0
        l1_reg: 1
        T: 1
        hidden_dim: 64
        num_coupling_blocks: 32
        num_layers_mlp: 2
    feat_opt: 
        lr: 0.000003
        n_iter: 500
        early_stop: 0
    prior_opt:
        n_iter: 1300
        lr: 0.000002
        noise_amp: 0.05
        weight_decay: 0.1
        early_stop: 0
    back_forth:
        n_back_forth: 3
        scheduler_step_size: 1
        scheduler_gamma: 0.5
        early_stop_fit: 0
        first_func_in_fit: "fit_feats"


MightyConfigs_bigclam:
    clamiter_init: 
        dim_feat: 24
        dim_attr: 100
        s_reg: 0.0
        l1_reg: 1
        T: 1
        hidden_dim: 64
        num_coupling_blocks: 32
        num_layers_mlp: 2
    feat_opt: 
        lr: 0.000001
        n_iter: 200
        early_stop: 0


MightyConfigs_pclam:
    clamiter_init: 
        dim_feat: 30
        dim_attr: 100
        s_reg: 0.0
        l1_reg: 1
        T: 1
        hidden_dim: 64
        num_coupling_blocks: 32
        num_layers_mlp: 2
    feat_opt: 
        lr: 0.000003
        n_iter: 500
        early_stop: 0
    prior_opt:
        n_iter: 1300
        lr: 0.0000002
        noise_amp: 0.05
        weight_decay: 0.1
        early_stop: 0
    back_forth:
        n_back_forth: 3
        scheduler_step_size: 1
        scheduler_gamma: 0.5
        early_stop_fit: 0
        first_func_in_fit: "fit_feats"
