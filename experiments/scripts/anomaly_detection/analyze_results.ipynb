{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.autograd import grad\n",
    "from torch_geometric.utils import subgraph\n",
    "from torch_geometric.transforms import TwoHop\n",
    "import numpy as np\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from inspect import currentframe, getframeinfo\n",
    "import os\n",
    "import sys\n",
    "from time import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "if '..' not in sys.path:\n",
    "    sys.path.insert(0, '../..')\n",
    "# Add the parent directory to sys.path\n",
    "print(sys.path)\n",
    "from utils.printing_utils import printd, filename_n_line_str\n",
    "\n",
    "from tests import tests\n",
    "from utils import utils\n",
    "from utils.plotting import *\n",
    "import anomaly_detection as ad\n",
    "from trainer import Trainer\n",
    "from scripting_utils import print_prior_training_stats\n",
    "from datasets.import_dataset import import_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if the new noise amp is any improvement.\n",
    "# change the config to also have an optimization config for fit prior fixed feats\n",
    "#todo: the mission now is to improve detection for small amount of nodes. i think that it means making the prior finer and maybe will need more layers and features\n",
    "# maybe we can think of features and layers as a type of frequency. \n",
    "\n",
    "#feeling lost. the noise amp doesn't work immediately. but the old one did work fine. maybe should first make the fit fixed prior stuff and test that the regular thing the last thing that worked still works just to be safe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMUNITIES AND N_ITER\n",
    "'''experiments from 14.7 with bigclam'''\n",
    "\n",
    "def get_k_mean_std(meas_array, verbose=False, ax=None, label=None):\n",
    "    ks = np.unique(meas_array[0])\n",
    "    ks_means_stds = np.zeros((3, len(ks)))\n",
    "    ks_means_stds[0] = ks\n",
    "    for i, k in enumerate(ks):\n",
    "        indices = np.where(meas_array[0] == k)\n",
    "        mean = np.mean(meas_array[1][indices])\n",
    "        std = np.std(meas_array[1][indices])\n",
    "        ks_means_stds[1, i] = mean\n",
    "        ks_means_stds[2, i] = std\n",
    "    if verbose:\n",
    "        '''notice we are using two sigma and not one'''\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "        ax.errorbar(ks_means_stds[0], ks_means_stds[1], yerr=2*ks_means_stds[2], label=label, linestyle='None', marker='o', capsize=7)\n",
    "        return ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GGAD datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#* if you take enough clusters, the averages will have a gaussian distribution\n",
    "# todo: i should probably pick these in some crossval process. like optimize everything and pick a test set or optimize and test on some subgraph\n",
    "\n",
    "path_bigclam_1700 = 'results/unsupervised/community_crossval/bigclam/1700/k_vs_auc_0.npy'\n",
    "path_bigclam_2000 = 'results/unsupervised/community_crossval/bigclam/2000/k_vs_auc_0.npy'\n",
    "path_bigclam_2500 = 'results/unsupervised/community_crossval/bigclam/2500/k_vs_auc_0.npy'\n",
    "\n",
    "path_bigclam_1701 = 'results/unsupervised/community_crossval/bigclam/1701/k_vs_auc_0.npy'\n",
    "path_bigclam_1900 = 'results/unsupervised/community_crossval/bigclam/1900/k_vs_auc_0.npy'\n",
    "path_bigclam_1300 = 'results/unsupervised/community_crossval/bigclam/1300/k_vs_auc_0.npy'\n",
    "\n",
    "\n",
    "path_ieclam_1700 = 'results/unsupervised/community_crossval/ieclam/1700/k_vs_auc_0.npy'\n",
    "path_ieclam_2000 = 'results/unsupervised/community_crossval/ieclam/2000/k_vs_auc_0.npy'\n",
    "path_ieclam_2500 = 'results/unsupervised/community_crossval/ieclam/2500/k_vs_auc_0.npy'\n",
    "\n",
    "\n",
    "\n",
    "bigclam_1700 = np.load(path_bigclam_1700)[:,1:]\n",
    "bigclam_2000 = np.load(path_bigclam_2000)[:,1:]\n",
    "bigclam_2500 = np.load(path_bigclam_2500)[:,1:]\n",
    "\n",
    "bigclam_1701 = np.load(path_bigclam_1701)[:,1:]\n",
    "bigclam_1900 = np.load(path_bigclam_1900)[:,1:]\n",
    "bigclam_1300 = np.load(path_bigclam_1300)[:,1:]\n",
    "\n",
    "ieclam_1700 = np.load(path_ieclam_1700)[:,1:]\n",
    "ieclam_2000 = np.load(path_ieclam_2000)[:,1:]\n",
    "ieclam_2500 = np.load(path_ieclam_2500)[:,1:]\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(bigclam_1700[0], bigclam_1700[1], label='1700')\n",
    "# plt.scatter(bigclam_2000[0], bigclam_2000[1], label='2000')\n",
    "# plt.scatter(bigclam_2500[0], bigclam_2500[1], label='2500')\n",
    "# plt.title('bigclam')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(bigclam_1701[0], bigclam_1701[1], label='1701')\n",
    "# plt.scatter(bigclam_1900[0], bigclam_1900[1], label='1900')\n",
    "# plt.scatter(bigclam_1300[0], bigclam_1300[1], label='1300')\n",
    "# plt.title('bigclam')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(ieclam_1700[0], ieclam_1700[1], label='1700')\n",
    "# plt.scatter(ieclam_2000[0], ieclam_2000[1], label='2000')\n",
    "# plt.scatter(ieclam_2500[0], ieclam_2500[1], label='2500')\n",
    "# plt.title('bigclam')\n",
    "# plt.legend()\n",
    "\n",
    "#todo: statistical analysis. think that the best will be to take mean - 2*sigma.\n",
    "#plot error bars\n",
    "ax = get_k_mean_std(bigclam_1700, verbose=True, label='1700')\n",
    "get_k_mean_std(bigclam_2000, verbose=True, ax=ax, label='2000')\n",
    "# get_k_mean_std(bigclam_2500, verbose=True, ax=ax, label='2500')\n",
    "plt.legend()\n",
    "plt.title('bigclam')\n",
    "\n",
    "ax = get_k_mean_std(bigclam_1701, verbose=True, label='1701')\n",
    "get_k_mean_std(bigclam_1900, verbose=True, ax=ax, label='1900')\n",
    "# get_k_mean_std(bigclam_1300, verbose=True, ax=ax, label='1300')\n",
    "plt.legend()\n",
    "plt.title('bigclam')\n",
    "\n",
    "ax = get_k_mean_std(ieclam_1700, verbose=True, label='1700')\n",
    "get_k_mean_std(ieclam_2000, verbose=True, ax=ax, label='2000')\n",
    "# get_k_mean_std(ieclam_2500, verbose=True, ax=ax, label='2500')\n",
    "plt.legend()\n",
    "plt.title('ieclam')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### elliptic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bigclam\n",
    "\n",
    "path_bigclam_elliptic_50 = 'unsupervised/find_communities/results/ellipticGGAD/bigclam/50/k_vs_auc_0.npy'\n",
    "path_bigclam_elliptic_100 = 'unsupervised/find_communities/results/ellipticGGAD/bigclam/100/k_vs_auc_0.npy'\n",
    "path_bigclam_elliptic_170 = 'unsupervised/find_communities/results/ellipticGGAD/bigclam/170/k_vs_auc_2.npy'\n",
    "path_bigclam_elliptic_200 = 'unsupervised/find_communities/results/ellipticGGAD/bigclam/200/k_vs_auc_0.npy'\n",
    "path_bigclam_elliptic_500 = 'unsupervised/find_communities/results/ellipticGGAD/bigclam/500/k_vs_auc_0.npy'\n",
    "\n",
    "path_bigclam_elliptic_1700 = 'unsupervised/find_communities/results/ellipticGGAD/bigclam/1700/k_vs_auc_0.npy'\n",
    "path_bigclam_elliptic_2000 = 'unsupervised/find_communities/results/ellipticGGAD/bigclam/2000/k_vs_auc_0.npy'\n",
    "\n",
    "bigclam_elliptic_50 = np.load(path_bigclam_elliptic_50)[:,:]\n",
    "bigclam_elliptic_100 = np.load(path_bigclam_elliptic_100)[:,:]\n",
    "bigclam_elliptic_170 = np.load(path_bigclam_elliptic_170)[:,:]\n",
    "bigclam_elliptic_200 = np.load(path_bigclam_elliptic_200)[:,:]\n",
    "bigclam_elliptic_500 = np.load(path_bigclam_elliptic_500)[:,:]\n",
    "\n",
    "bigclam_elliptic_1700 = np.load(path_bigclam_elliptic_1700)[:,:]\n",
    "bigclam_elliptic_2000 = np.load(path_bigclam_elliptic_2000)[:,:]\n",
    "\n",
    "#todo: statistical analysis. think that the best will be to take mean - 2*sigma.\n",
    "#plot error bars\n",
    "ax = get_k_mean_std(bigclam_elliptic_50, verbose=True, label='50')\n",
    "get_k_mean_std(bigclam_elliptic_100, verbose=True, ax=ax, label='100')\n",
    "get_k_mean_std(bigclam_elliptic_170, verbose=True, ax=ax, label='170')\n",
    "get_k_mean_std(bigclam_elliptic_200, verbose=True, ax=ax, label='200')\n",
    "get_k_mean_std(bigclam_elliptic_500, verbose=True, ax=ax, label='500')\n",
    "get_k_mean_std(bigclam_elliptic_1700, verbose=True, ax=ax, label='1700')\n",
    "get_k_mean_std(bigclam_elliptic_2000, verbose=True, ax=ax, label='2000')\n",
    "# get_k_mean_std(bigclam_2500, verbose=True, ax=ax, label='2500')\n",
    "plt.legend()\n",
    "plt.title('bigclam')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ieclam\n",
    "\n",
    "path_ieclam_50 = 'unsupervised/find_communities/results/ellipticGGAD/ieclam/50/k_vs_auc_0.npy'\n",
    "path_ieclam_100 = 'unsupervised/find_communities/results/ellipticGGAD/ieclam/100/k_vs_auc_0.npy'\n",
    "path_ieclam_170 = 'unsupervised/find_communities/results/ellipticGGAD/ieclam/170/k_vs_auc_0.npy'\n",
    "path_ieclam_200 = 'unsupervised/find_communities/results/ellipticGGAD/ieclam/200/k_vs_auc_0.npy'\n",
    "path_ieclam_500 = 'unsupervised/find_communities/results/ellipticGGAD/ieclam/500/k_vs_auc_0.npy'\n",
    "path_ieclam_1700 = 'unsupervised/find_communities/results/ellipticGGAD/ieclam/1700/k_vs_auc_0.npy'\n",
    "\n",
    "ieclam_50 = np.load(path_ieclam_50)[:,:]\n",
    "ieclam_100 = np.load(path_ieclam_100)[:,:]\n",
    "ieclam_170 = np.load(path_ieclam_170)[:,:]\n",
    "ieclam_200 = np.load(path_ieclam_200)[:,:]\n",
    "ieclam_500 = np.load(path_ieclam_500)[:,:]\n",
    "ieclam_1700 = np.load(path_ieclam_1700)[:,:]\n",
    "\n",
    "#todo: statistical analysis. think that the best will be to take mean - 2*sigma.\n",
    "#plot error bars\n",
    "ax = get_k_mean_std(ieclam_50, verbose=True, label='50')\n",
    "get_k_mean_std(ieclam_100, verbose=True, ax=ax, label='100')\n",
    "get_k_mean_std(ieclam_170, verbose=True, ax=ax, label='170')\n",
    "get_k_mean_std(ieclam_200, verbose=True, ax=ax, label='200')\n",
    "get_k_mean_std(ieclam_500, verbose=True, ax=ax, label='500')\n",
    "get_k_mean_std(ieclam_1700, verbose=True, ax=ax, label='1700')\n",
    "plt.legend()\n",
    "plt.title('ieclam')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### photoGGAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_bigclam_photo_1700 = 'unsupervised/find_communities/results/photoGGAD/bigclam/1700/k_vs_auc_0.npy'\n",
    "\n",
    "\n",
    "path_bigclam_photo_2000 = 'unsupervised/find_communities/results/photoGGAD/bigclam/2000/k_vs_auc_0.npy'\n",
    "\n",
    "\n",
    "bigclam_photo_1700 = np.load(path_bigclam_photo_1700)\n",
    "bigclam_photo_2000 = np.load(path_bigclam_photo_2000)\n",
    "\n",
    "#todo: statistical analysis. think that the best will be to take mean - 2*sigma.\n",
    "#plot error bars\n",
    "\n",
    "ax = get_k_mean_std(bigclam_photo_1700, verbose=True, label='1700')\n",
    "get_k_mean_std(bigclam_photo_2000, verbose=True, ax=ax, label='2000')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('bigclam')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfFinanceGGAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ieclam_50 = 'unsupervised/find_communities/results/tfFinanceGGAD/ieclam/50/k_vs_auc_0.npy'\n",
    "path_ieclam_100 = 'unsupervised/find_communities/results/tfFinanceGGAD/ieclam/100/k_vs_auc_0.npy'\n",
    "path_ieclam_170 = 'unsupervised/find_communities/results/tfFinanceGGAD/ieclam/170/k_vs_auc_0.npy'\n",
    "path_ieclam_200 = 'unsupervised/find_communities/results/tfFinanceGGAD/ieclam/200/k_vs_auc_0.npy'\n",
    "path_ieclam_500 = 'unsupervised/find_communities/results/tfFinanceGGAD/ieclam/500/k_vs_auc_0.npy'\n",
    "path_ieclam_1700 = 'unsupervised/find_communities/results/tfFinanceGGAD/ieclam/1700/k_vs_auc_0.npy'\n",
    "\n",
    "ieclam_50 = np.load(path_ieclam_50)[:,:]\n",
    "ieclam_100 = np.load(path_ieclam_100)[:,:]\n",
    "ieclam_170 = np.load(path_ieclam_170)[:,:]\n",
    "ieclam_200 = np.load(path_ieclam_200)[:,:]\n",
    "ieclam_500 = np.load(path_ieclam_500)[:,:]\n",
    "ieclam_1700 = np.load(path_ieclam_1700)[:,:]\n",
    "\n",
    "#todo: statistical analysis. think that the best will be to take mean - 2*sigma.\n",
    "#plot error bars\n",
    "ax = get_k_mean_std(ieclam_50, verbose=True, label='50')\n",
    "get_k_mean_std(ieclam_100, verbose=True, ax=ax, label='100')\n",
    "get_k_mean_std(ieclam_170, verbose=True, ax=ax, label='170')\n",
    "get_k_mean_std(ieclam_200, verbose=True, ax=ax, label='200')\n",
    "get_k_mean_std(ieclam_500, verbose=True, ax=ax, label='500')\n",
    "get_k_mean_std(ieclam_1700, verbose=True, ax=ax, label='1700')\n",
    "plt.legend()\n",
    "plt.title('ieclam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_bigclam_50 = 'unsupervised/find_communities/results/tfFinanceGGAD/bigclam/50/k_vs_auc_0.npy'\n",
    "path_bigclam_100 = 'unsupervised/find_communities/results/tfFinanceGGAD/bigclam/100/k_vs_auc_0.npy'\n",
    "path_bigclam_170 = 'unsupervised/find_communities/results/tfFinanceGGAD/bigclam/170/k_vs_auc_0.npy'\n",
    "path_bigclam_200 = 'unsupervised/find_communities/results/tfFinanceGGAD/bigclam/200/k_vs_auc_0.npy'\n",
    "path_bigclam_500 = 'unsupervised/find_communities/results/tfFinanceGGAD/bigclam/500/k_vs_auc_0.npy'\n",
    "path_bigclam_1700 = 'unsupervised/find_communities/results/tfFinanceGGAD/bigclam/1700/k_vs_auc_0.npy'\n",
    "\n",
    "bigclam_50 = np.load(path_bigclam_50)[:,:]\n",
    "bigclam_100 = np.load(path_bigclam_100)[:,:]\n",
    "bigclam_170 = np.load(path_bigclam_170)[:,:]\n",
    "bigclam_200 = np.load(path_bigclam_200)[:,:]\n",
    "bigclam_500 = np.load(path_bigclam_500)[:,:]\n",
    "bigclam_1700 = np.load(path_bigclam_1700)[:,:]\n",
    "\n",
    "#todo: statistical analysis. think that the best will be to take mean - 2*sigma.\n",
    "#plot error bars\n",
    "ax = get_k_mean_std(bigclam_50, verbose=True, label='50')\n",
    "get_k_mean_std(bigclam_100, verbose=True, ax=ax, label='100')\n",
    "get_k_mean_std(bigclam_170, verbose=True, ax=ax, label='170')\n",
    "get_k_mean_std(bigclam_200, verbose=True, ax=ax, label='200')\n",
    "get_k_mean_std(bigclam_500, verbose=True, ax=ax, label='500')\n",
    "get_k_mean_std(bigclam_1700, verbose=True, ax=ax, label='1700')\n",
    "plt.legend()\n",
    "plt.title('bigclam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### redditGGAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ieclam_reddit_1700 = 'unsupervised/find_communities/results/redditGGAD/ieclam/1700/k_vs_auc_0.npy'\n",
    "\n",
    "\n",
    "bigclam_reddit_1700 = np.load(path_ieclam_reddit_1700)[:,:-20]\n",
    "\n",
    "#todo: statistical analysis. think that the best will be to take mean - 2*sigma.\n",
    "#plot error bars\n",
    "\n",
    "ax = get_k_mean_std(bigclam_reddit_1700, verbose=True, label='1700')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('reddit ieclam')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic from Dominant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flickr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_bigclam_flickr_1700 = 'unsupervised/find_communities/results/Flickr/bigclam/1700/k_vs_auc_0.npy'\n",
    "\n",
    "\n",
    "path_bigclam_flickr_2000 = 'unsupervised/find_communities/results/Flickr/bigclam/2000/k_vs_auc_0.npy'\n",
    "\n",
    "\n",
    "bigclam_flickr_1700 = np.load(path_bigclam_flickr_1700)\n",
    "bigclam_flickr_2000 = np.load(path_bigclam_flickr_2000)\n",
    "\n",
    "#todo: statistical analysis. think that the best will be to take mean - 2*sigma.\n",
    "#plot error bars\n",
    "\n",
    "ax = get_k_mean_std(bigclam_flickr_1700, verbose=True, label='1700')\n",
    "get_k_mean_std(bigclam_flickr_2000, verbose=True, ax=ax, label='2000')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('bigclam')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BlogCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_bigclam_BlogCatalog_1700 = 'unsupervised/find_communities/results/BlogCatalog/bigclam/1700/k_vs_auc_0.npy'\n",
    "path_bigclam_BlogCatalog_2000 = 'unsupervised/find_communities/results/BlogCatalog/bigclam/2000/k_vs_auc_0.npy'\n",
    "\n",
    "bigclam_BlogCatalog_1700 = np.load(path_bigclam_BlogCatalog_1700)\n",
    "bigclam_BlogCatalog_2000 = np.load(path_bigclam_BlogCatalog_2000)\n",
    "\n",
    "#todo: statistical analysis. think that the best will be to take mean - 2*sigma.\n",
    "#plot error bars\n",
    "\n",
    "ax = get_k_mean_std(bigclam_BlogCatalog_1700, verbose=True, label='1700')\n",
    "get_k_mean_std(bigclam_BlogCatalog_2000, verbose=True, ax=ax, label='2000')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('bigclam')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_bigclam_ACM_1700 = 'unsupervised/find_communities/results/ACM/bigclam/1700/k_vs_auc_0.npy'\n",
    "path_bigclam_ACM_2000 = 'unsupervised/find_communities/results/ACM/bigclam/2000/k_vs_auc_0.npy'\n",
    "\n",
    "bigclam_ACM_1700 = np.load(path_bigclam_ACM_1700)\n",
    "bigclam_ACM_2000 = np.load(path_bigclam_ACM_2000)\n",
    "\n",
    "#todo: statistical analysis. think that the best will be to take mean - 2*sigma.\n",
    "#plot error bars\n",
    "\n",
    "ax = get_k_mean_std(bigclam_ACM_1700, verbose=True, label='1700')\n",
    "get_k_mean_std(bigclam_ACM_2000, verbose=True, ax=ax, label='2000')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('bigclam')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Setting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = 'bigclam_then_prior3/results/losses/losses_16_16_2.txt'\n",
    "array = np.loadtxt(file_path)\n",
    "\n",
    "plt.plot(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: more experiments with 32 32 2 0.01. also try 64 32 2 0.01 and all the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data(file_path, figsize=(12, 6)):\n",
    "    array = np.loadtxt(file_path, comments='#')\n",
    "\n",
    "    # Extract the file name from the file path\n",
    "    file_name = os.path.basename(file_path)\n",
    "\n",
    "    # Create a figure with two subplots\n",
    "    fig, _ = plt.subplots(1, 2, figsize=figsize)\n",
    "\n",
    "    # Define the colors for the plots\n",
    "    colors = ['blue', 'orange', 'green', 'red']\n",
    "\n",
    "    # Plot the columns of the array in the first subplot\n",
    "    for i in range(1, array.shape[1]):\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(array[:, 0], array[:, i], color=colors[i-1])\n",
    "\n",
    "    # Add legend and labels to the first subplot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.legend(['base vanilla', 'vanilla star', 'prior', 'prior star'])\n",
    "    plt.xlabel('Index')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.ylabel('Value')\n",
    "    plt.ylim(0.6, 1.02)\n",
    "\n",
    "    new_array = array[:, 2:] / array[:, 1].reshape(-1, 1)\n",
    "\n",
    "    # Plot the columns of the array in the second subplot\n",
    "    for i in range(new_array.shape[1]):\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(array[:, 0], new_array[:, i], color=colors[i+1])\n",
    "\n",
    "    # Add legend and labels to the second subplot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.legend(['vanilla_star', 'prior', 'prior star'])\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Value')\n",
    "    plt.ylim(0.5, 1.5)\n",
    "\n",
    "    # Add vertical lines to each element of array[:, 0]\n",
    "    for x in array[:, 0]:\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.axvline(x, color='gray', linestyle='--')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.axvline(x, color='gray', linestyle='--')\n",
    "\n",
    "    # Set the title of the plot as the file name\n",
    "    plt.suptitle(file_name)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Plot the file path using the function\n",
    "plot_data('results/avg_deg_tables/8_8_2_0.01_hyperbolic_inflate.txt', figsize=(6, 3))\n",
    "plot_data('results/avg_deg_tables/32_32_2_0.01_hyperbolic_inflate.txt', figsize=(6, 3))\n",
    "plot_data('results/avg_deg_tables/32_32_2_0.05.txt', figsize=(6, 3))\n",
    "\n",
    "# Plot the file path that is plotted using the function\n",
    "plot_data('results/avg_deg_tables/32_32_2_0.01.txt', figsize=(6, 3))\n",
    "\n",
    "plot_data('results/avg_deg_tables/32_32_3_0.01.txt', figsize=(6, 3))\n",
    "plot_data('results/avg_deg_tables/32_32_3_0.05.txt', figsize=(6, 3))\n",
    "plot_data('results/avg_deg_tables/64_32_2_0.05.txt', figsize=(6, 3))\n",
    "plot_data('results/avg_deg_tables/32_64_2_0.05.txt', figsize=(6, 3))\n",
    "plot_data('results/avg_deg_tables/64_64_2_0.05.txt', figsize=(6, 3))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: maybe it will make sense to show relative improvement\n",
    "\n",
    "folder_path = 'results/avg_deg_tables/32_32_2_0.05.txt'\n",
    "array = np.loadtxt(folder_path, comments='#')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the columns of the array\n",
    "for i in range(1,array.shape[1]):\n",
    "    plt.plot(array[:,0],array[:, i])\n",
    "\n",
    "# Add legend and labels\n",
    "plt.legend(['base vanilla', 'vanilla star', 'prior', 'prior star'])\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "\n",
    "plt.ylim(0.6, 1.02)\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: maybe it will make sense to show relative improvement\n",
    "\n",
    "folder_path = 'results/avg_deg_tables/32_32_3_0.01.txt'\n",
    "array = np.loadtxt(folder_path, comments='#')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the columns of the array\n",
    "for i in range(1,array.shape[1]):\n",
    "    plt.plot(array[:,0],array[:, i])\n",
    "\n",
    "# Add legend and labels\n",
    "plt.legend(['base vanilla', 'vanilla star', 'prior', 'prior star'])\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.ylim(0.6, 1.02)\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: maybe it will make sense to show relative improvement\n",
    "\n",
    "folder_path = 'results/avg_deg_tables/32_32_3_0.05.txt'\n",
    "array = np.loadtxt(folder_path, comments='#')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the columns of the array\n",
    "for i in range(1,array.shape[1]):\n",
    "    plt.plot(array[:,0],array[:, i])\n",
    "\n",
    "# Add legend and labels\n",
    "plt.legend(['base vanilla', 'vanilla star', 'prior', 'prior star'])\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.ylim(0.6, 1.02)\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: maybe it will make sense to show relative improvement\n",
    "\n",
    "folder_path = 'results/avg_deg_tables/32_64_2_0.05.txt'\n",
    "array = np.loadtxt(folder_path, comments='#')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the columns of the array\n",
    "for i in range(1,array.shape[1]):\n",
    "    plt.plot(array[:,0],array[:, i])\n",
    "\n",
    "# Add legend and labels\n",
    "plt.legend(['base vanilla', 'vanilla star', 'prior', 'prior star'])\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.ylim(0.6, 1.02)\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: maybe it will make sense to show relative improvement\n",
    "\n",
    "folder_path = 'results/avg_deg_tables/64_32_2_0.05.txt'\n",
    "array = np.loadtxt(folder_path, comments='#')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the columns of the array\n",
    "for i in range(1,array.shape[1]):\n",
    "    plt.plot(array[:,0],array[:, i])\n",
    "\n",
    "# Add legend and labels\n",
    "plt.legend(['base vanilla', 'vanilla star', 'prior', 'prior star'])\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.ylim(0.6, 1.02)\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: maybe it will make sense to show relative improvement\n",
    "\n",
    "folder_path = 'results/avg_deg_tables/64_64_2_0.05.txt'\n",
    "array = np.loadtxt(folder_path, comments='#')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the columns of the array\n",
    "for i in range(1,array.shape[1]):\n",
    "    plt.plot(array[:,0],array[:, i])\n",
    "\n",
    "# Add legend and labels\n",
    "plt.legend(['base vanilla', 'vanilla star', 'prior', 'prior star'])\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.ylim(0.6, 1.02)\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
