{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "# local\n",
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.insert(0, '..')\n",
    "\n",
    "from datasets.import_dataset import import_dataset\n",
    "from trainer import Trainer\n",
    "import clamiter as ci\n",
    "from utils.plotting import *\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'device = {device}')\n",
    "from datasets.simulations import create_sbm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distance_experiment(0.01, 'find_d', ds_name='squirrel', range=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Experiment: for every dataset we used find the best d and see that the log cut converges.'''\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#\n",
    "for ds_name in ['squirrel']:\n",
    "    for model_name in ['ieclam']:\n",
    "        ds = import_dataset(ds_name)\n",
    "\n",
    "\n",
    "        # SBM\n",
    "        config_triplets = [\n",
    "                            ['feat_opt', 'n_iter', 15000],\n",
    "                            # ['feat_opt', 'lr', 0.00005],\n",
    "                            # ['prior_opt', 'n_iter', 1500],\n",
    "                            # ['prior_opt', 'lr', 0.0000005],\n",
    "                            # ['back_forth','n_back_forth', 30],\n",
    "                            # ['back_forth', 'first_func_in_fit', 'feat_opt']\n",
    "                          ]\n",
    "\n",
    "        for d in [0.0005, 0.001, 0.0001]:\n",
    "            printd(f'{d=}')\n",
    "            trainer = Trainer(\n",
    "                        model_name=model_name,\n",
    "                        task='distance',\n",
    "                        device=device,\n",
    "                        config_triplets_to_change=config_triplets,\n",
    "                        dataset=ds.clone()\n",
    "            )\n",
    "            # i want to optimize the trainer\n",
    "            log_likelihoods, test_accs, val_accs = trainer.train(\n",
    "                d=d,\n",
    "                plot_every=-1,\n",
    "                init_feats=True,\n",
    "                init_type='small_gaus',\n",
    "                verbose=False,\n",
    "                acc_every=100,\n",
    "                verbose_in_funcs=False\n",
    "            )\n",
    "\n",
    "            log_likelihoods = np.array(log_likelihoods)/(ds.num_nodes**2)\n",
    "\n",
    "\n",
    "            dir_path = f'results/distance/find_d/{ds_name}/{model_name}/d_{d}'\n",
    "            if not os.path.exists(dir_path):\n",
    "                os.makedirs(dir_path)\n",
    "            torch.save(test_accs['log_cut'], dir_path + f'/logcuts.pt')\n",
    "            torch.save(log_likelihoods, dir_path + f'/log_likelihoods.pt')\n",
    "            torch.save(val_accs['l2'], dir_path + f'/l2s.pt')\n",
    "            \n",
    "            del trainer.data\n",
    "            if trainer.clamiter.prior is not None:\n",
    "                del trainer.clamiter.prior.model\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Experiment: for every dataset we used find the best d and see that the log cut converges.'''\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#\n",
    "for ds_name in ['photo', 'sbm3x3HalfDiag']:\n",
    "    for model_name in ['ieclam']:\n",
    "        ds = import_dataset(ds_name)\n",
    "\n",
    "\n",
    "        # SBM\n",
    "        config_triplets = [\n",
    "                            ['feat_opt', 'n_iter', 5000],\n",
    "                            ['feat_opt', 'lr', 0.00005],\n",
    "                            # ['prior_opt', 'n_iter', 1500],\n",
    "                            # ['prior_opt', 'lr', 0.0000005],\n",
    "                            # ['back_forth','n_back_forth', 30],\n",
    "                            # ['back_forth', 'first_func_in_fit', 'feat_opt']\n",
    "                          ]\n",
    "\n",
    "        for d in [0.0005, 0.001, 0.0001]:\n",
    "            printd(f'{d=}')\n",
    "            trainer = Trainer(\n",
    "                        model_name=model_name,\n",
    "                        task='distance',\n",
    "                        device=device,\n",
    "                        config_triplets_to_change=config_triplets,\n",
    "                        dataset=ds.clone()\n",
    "            )\n",
    "            # i want to optimize the trainer\n",
    "            log_likelihoods, test_accs, val_accs = trainer.train(\n",
    "                d=d,\n",
    "                plot_every=-1,\n",
    "                init_feats=True,\n",
    "                init_type='small_gaus',\n",
    "                verbose=False,\n",
    "                acc_every=100,\n",
    "                verbose_in_funcs=False\n",
    "            )\n",
    "\n",
    "            log_likelihoods = np.array(log_likelihoods)/(ds.num_nodes**2)\n",
    "\n",
    "\n",
    "            dir_path = f'results/distance/find_d/{ds_name}/{model_name}/d_{d}'\n",
    "            if not os.path.exists(dir_path):\n",
    "                os.makedirs(dir_path)\n",
    "            torch.save(test_accs['log_cut'], dir_path + f'/logcuts.pt')\n",
    "            torch.save(log_likelihoods, dir_path + f'/log_likelihoods.pt')\n",
    "            torch.save(val_accs['l2'], dir_path + f'/l2s.pt')\n",
    "            \n",
    "            del trainer.data\n",
    "            if trainer.clamiter.prior is not None:\n",
    "                del trainer.clamiter.prior.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distance_experiment(0.01, 'train_to_overfit', 'squirrel', 'ieclam', 4900)\n",
    "\n",
    "#? experimental insight: the approximation matrix reaches values of 1 via the log likelihood optimization in which case the log cut is infinity. so the limitation is also via the step size..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Experiment: try and get overfitting in the log cut distance. If we train the model for long enough, we expect that the log cut will start increasing because of overfitting so we are training it for a very long time.'''\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "model_name = 'ieclam'\n",
    "ds = import_dataset('squirrel')\n",
    "d = 0.005\n",
    "n_iter = 45000\n",
    "config_triplets = [\n",
    "                    ['feat_opt', 'n_iter', n_iter],\n",
    "                    # ['feat_opt', 'lr', 0.00005],\n",
    "                    # ['prior_opt', 'n_iter', 1500],\n",
    "                    # ['prior_opt', 'lr', 0.0000005],\n",
    "                    # ['back_forth','n_back_forth', 30],\n",
    "                    # ['back_forth', 'first_func_in_fit', 'feat_opt']\n",
    "                ]\n",
    "\n",
    "trainer = Trainer(\n",
    "            model_name=model_name,\n",
    "            task='distance',\n",
    "            device=device,\n",
    "            config_triplets_to_change=config_triplets,\n",
    "            dataset=ds.clone()\n",
    ")\n",
    "# i want to optimize the trainer\n",
    "try:\n",
    "    log_likelihoods, test_accs, val_accs = trainer.train(\n",
    "        d=d,\n",
    "        plot_every=-1,\n",
    "        init_feats=True,\n",
    "        init_type='small_gaus',\n",
    "        verbose=False,\n",
    "        acc_every=100,\n",
    "        verbose_in_funcs=False\n",
    "    )\n",
    "\n",
    "    log_likelihoods = np.array(log_likelihoods)/(ds.num_nodes**2)\n",
    "except Exception as e:\n",
    "    raise\n",
    "\n",
    "finally:\n",
    "    dir_path = f'results/distance/train_to_overfit/squirrel/ieclam/d_{d}/n_iter_{n_iter}/{datetime.now().strftime(\"%Y-%m-%d_%H-%M\")}'\n",
    "    \n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "    torch.save(test_accs['log_cut'], dir_path + f'/logcuts')\n",
    "    torch.save(log_likelihoods, dir_path + f'/log_likelihoods')\n",
    "    torch.save(val_accs['l2'], dir_path + f'/l2s')\n",
    "\n",
    "    del trainer.data\n",
    "    if trainer.clamiter.prior is not None:\n",
    "        del trainer.clamiter.prior.model\n",
    "\n",
    "    #todo: print every 1000 iterations\n",
    "    #todo: find where it gets infinity (and what,,,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_accs['log_cut'][400:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sbm and bipartite\n",
    "ds_sbm_halfdiag = import_dataset('sbm3x3HalfDiag')\n",
    "ds_sbm_halfcenter = import_dataset('sbm3x3HalfCenter')\n",
    "\n",
    "# plot_adj(ds_sbm_halfcenter.edge_index, ax=axes[0])\n",
    "# plot_adj(ds_sbm_halfdiag.edge_index, ax=axes[1])\n",
    "\n",
    "# create sbm\n",
    "prob_adj_3X3, y = create_sbm(70, p_comm=[0.0, 0.0, 0.0], p_bipart=[0.5, 0.5, 0.5]) \n",
    "plot_adj(prob_adj_3X3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lorenz Inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IEClam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_triplets = [\n",
    "                    ['feat_opt', 'n_iter', 15000],\n",
    "                    # ['feat_opt', 'lr', 0.00003],\n",
    "                    # ['prior_opt', 'lr', 0.0000005],\n",
    "                    # ['back_forth','n_back_forth', 5],\n",
    "                    # ['back_forth', 'first_func_in_fit', 'feat_opt']\n",
    "                ]\n",
    "\n",
    "\n",
    "trainer_halfdiag_ieclam = Trainer(\n",
    "                model_name='ieclam',\n",
    "                task='distance',\n",
    "                device=device,\n",
    "                config_triplets_to_change=config_triplets,\n",
    "                dataset=ds_sbm_halfdiag.clone()\n",
    "                \n",
    ")\n",
    "\n",
    "losses_halfdiag_ieclam, logcut_halfdiag_ieclam, l2_halfdiag_ieclam = trainer_halfdiag_ieclam.train(\n",
    "    d = 0.01,\n",
    "    plot_every=-1,\n",
    "    init_feats=True,\n",
    "    init_type='small_gaus',\n",
    "    acc_every=500,\n",
    "    verbose=False,\n",
    "    verbose_in_funcs=False\n",
    ")\n",
    "\n",
    "# todo: move the contents of train into fit and then do trainer.clamiter.fit() not urgent. add an option for trainer to do cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PieClam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_triplets = [\n",
    "                    # ['feat_opt', 'n_iter', 200],\n",
    "                    ['clamiter_init', 'dim_feat', 6],\n",
    "                    ['feat_opt', 'lr', 0.0001],\n",
    "                    # ['prior_opt', 'n_iter', 150],\n",
    "                    ['prior_opt', 'lr', 0.00001],\n",
    "                    ['back_forth','n_back_forth', 5],\n",
    "                    # ['back_forth', 'first_func_in_fit', 'feat_opt']\n",
    "                ]\n",
    "\n",
    "\n",
    "trainer_halfdiag_pieclam = Trainer(\n",
    "                model_name='pieclam',\n",
    "                task='distance',\n",
    "                device=device,\n",
    "                config_triplets_to_change=config_triplets,\n",
    "                dataset=ds_sbm_halfdiag\n",
    ")\n",
    "\n",
    "losses_halfdiag_pieclam, logcut_halfdiag_pieclam, l2_halfdiag_pieclam = trainer_halfdiag_pieclam.train(\n",
    "    d = 0.2,\n",
    "    plot_every=1,\n",
    "    init_feats=True,\n",
    "    init_type='small_gaus',\n",
    "    verbose=False,\n",
    "    verbose_in_funcs=False,\n",
    "    node_size_factor=5,\n",
    "    draw_edges=False\n",
    "    \n",
    "    \n",
    ")\n",
    "del trainer_halfdiag_pieclam.data   \n",
    "del trainer_halfdiag_pieclam.clamiter.prior.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inner Prod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BIGCLAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_triplets = [\n",
    "                    # ['feat_opt', 'n_iter', 2000],\n",
    "                    # ['feat_opt', 'lr', 0.00003],\n",
    "                    # ['prior_opt', 'n_iter', 1500],\n",
    "                    # ['prior_opt', 'lr', 0.0000005],\n",
    "                    # ['back_forth','n_back_forth', 50],\n",
    "                    # ['back_forth', 'first_func_in_fit', 'feat_opt']\n",
    "                ]\n",
    "\n",
    "\n",
    "trainer_halfdiag_bigclam= Trainer(\n",
    "                model_name='bigclam',\n",
    "                task='distance',\n",
    "                device=device,\n",
    "                config_triplets_to_change=config_triplets,\n",
    "                dataset=ds_sbm_halfdiag.clone()\n",
    ")\n",
    "\n",
    "losses_halfdiag_bigclam, logcut_halfdiag_bigclam, l2_halfdiag_bigclam = trainer_halfdiag_bigclam.train(\n",
    "    d = 0.2,\n",
    "    plot_every=-1,\n",
    "    init_feats=True,\n",
    "    init_type='small_gaus',\n",
    "    verbose=False,\n",
    "    verbose_in_funcs=False\n",
    ")\n",
    "\n",
    "del trainer_halfdiag_bigclam.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PClam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SBM\n",
    "config_triplets = [\n",
    "                    ['clamiter_init', 'dim_feat', 6],\n",
    "                    # ['feat_opt', 'n_iter', 2000],\n",
    "                    # ['feat_opt', 'lr', 0.00003],\n",
    "                    # ['prior_opt', 'n_iter', 1500],\n",
    "                    # ['prior_opt', 'lr', 0.0000005],\n",
    "                    ['back_forth','n_back_forth', 1],\n",
    "                    # ['back_forth', 'first_func_in_fit', 'feat_opt']\n",
    "                ]\n",
    "\n",
    "\n",
    "trainer_halfdiag_pclam = Trainer(\n",
    "                model_name='pclam',\n",
    "                task='distance',\n",
    "                device=device,\n",
    "                config_triplets_to_change=config_triplets,\n",
    "                dataset=ds_sbm_halfdiag.clone()\n",
    ")\n",
    "# i want to optimize the trainer\n",
    "losses_halfdiag_pclam, logcut_halfdiag_pclam, l2_halfdiag_pclam = trainer_halfdiag_pclam.train(\n",
    "    d = 0.2,\n",
    "    plot_every=1,\n",
    "    init_feats=True,\n",
    "    init_type='small_gaus',\n",
    "    verbose=False,\n",
    "    verbose_in_funcs=False\n",
    ")\n",
    "del trainer_halfdiag_pclam.data\n",
    "del trainer_halfdiag_pclam.clamiter.prior.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lorenz Inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IEClam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_triplets = [\n",
    "                    # ['feat_opt', 'n_iter', 2000],\n",
    "                    # ['feat_opt', 'lr', 0.00003],\n",
    "                    # ['prior_opt', 'n_iter', 1500],\n",
    "                    # ['prior_opt', 'lr', 0.0000005],\n",
    "                    # ['back_forth','n_back_forth', 50],\n",
    "                    # ['back_forth', 'first_func_in_fit', 'feat_opt']\n",
    "                ]\n",
    "\n",
    "\n",
    "trainer_halfdiag_ieclam = Trainer(\n",
    "                model_name='ieclam',\n",
    "                task='distance',\n",
    "                device=device,\n",
    "                config_triplets_to_change=config_triplets,\n",
    "                dataset=ds_sbm_halfdiag.clone()\n",
    ")\n",
    "\n",
    "losses_halfdiag_ieclam, logcut_halfdiag_ieclam, l2_halfdiag_ieclam = trainer_halfdiag_ieclam.train(\n",
    "    d = 0.2,\n",
    "    plot_every=-1,\n",
    "    init_feats=True,\n",
    "    init_type='small_gaus',\n",
    "    verbose=False,\n",
    "    verbose_in_funcs=False\n",
    ")\n",
    "\n",
    "del trainer_halfdiag_ieclam.data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PieClam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_triplets = [\n",
    "                    # ['feat_opt', 'n_iter', 2000],\n",
    "                    # ['feat_opt', 'lr', 0.00003],\n",
    "                    # ['prior_opt', 'n_iter', 1500],\n",
    "                    # ['prior_opt', 'lr', 0.0000005],\n",
    "                    # ['back_forth','n_back_forth', 50],\n",
    "                    # ['back_forth', 'first_func_in_fit', 'feat_opt']\n",
    "                ]\n",
    "\n",
    "\n",
    "trainer_halfdiag_pieclam = Trainer(\n",
    "                model_name='pieclam',\n",
    "                task='distance',\n",
    "                device=device,\n",
    "                config_triplets_to_change=config_triplets,\n",
    "                dataset=ds_sbm_halfdiag.clone()\n",
    ")\n",
    "\n",
    "losses_halfdiag_pieclam, logcut_halfdiag_pieclam, l2_halfdiag_pieclam = trainer_halfdiag_pieclam.train(\n",
    "    d = 0.2,\n",
    "    plot_every=-1,\n",
    "    init_feats=True,\n",
    "    init_type='small_gaus',\n",
    "    verbose=False,\n",
    "    verbose_in_funcs=False\n",
    ")\n",
    "\n",
    "del trainer_halfdiag_pieclam.data\n",
    "del trainer_halfdiag_pieclam.clamiter.prior.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HalfCenter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lorenz Inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IEClam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_triplets = [\n",
    "                    # ['feat_opt', 'n_iter', 2000],\n",
    "                    # ['feat_opt', 'lr', 0.00003],\n",
    "                    # ['prior_opt', 'n_iter', 1500],\n",
    "                    # ['prior_opt', 'lr', 0.0000005],\n",
    "                    # ['back_forth','n_back_forth', 50],\n",
    "                    # ['back_forth', 'first_func_in_fit', 'feat_opt']\n",
    "                ]\n",
    "\n",
    "\n",
    "trainer_halfcenter_ieclam = Trainer(\n",
    "                model_name='ieclam',\n",
    "                task='distance',\n",
    "                device=device,\n",
    "                config_triplets_to_change=config_triplets,\n",
    "                dataset=ds_sbm_halfcenter.clone()\n",
    ")\n",
    "\n",
    "losses_halfcenter_ieclam, logcut_halfcenter_ieclam, l2_halfcenter_ieclam = trainer_halfcenter_ieclam.train(\n",
    "    d = 0.2,\n",
    "    plot_every=-1,\n",
    "    init_feats=True,\n",
    "    init_type='small_gaus',\n",
    "    verbose=False,\n",
    "    verbose_in_funcs=False\n",
    ")\n",
    "del trainer_halfcenter_ieclam.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PieClam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_triplets = [\n",
    "                    # ['feat_opt', 'n_iter', 200],\n",
    "                    ['feat_opt', 'lr', 0.0001],\n",
    "                    # ['prior_opt', 'n_iter', 150],\n",
    "                    ['prior_opt', 'lr', 0.00001],\n",
    "                    ['back_forth','n_back_forth', 5],\n",
    "                    # ['back_forth', 'first_func_in_fit', 'feat_opt']\n",
    "                ]\n",
    "\n",
    "\n",
    "trainer_halfcenter_pieclam = Trainer(\n",
    "                model_name='pieclam',\n",
    "                task='distance',\n",
    "                device=device,\n",
    "                config_triplets_to_change=config_triplets,\n",
    "                dataset=ds_sbm_halfcenter.clone()\n",
    ")\n",
    "\n",
    "losses_halfcenter_pieclam, logcut_halfcenter_pieclam, l2_halfcenter_pieclam = trainer_halfcenter_pieclam.train(\n",
    "    d = 0.2,\n",
    "    plot_every=-1,\n",
    "    init_feats=True,\n",
    "    init_type='small_gaus',\n",
    "    verbose=False,\n",
    "    verbose_in_funcs=False\n",
    ")\n",
    "del trainer_halfcenter_pieclam.data\n",
    "del trainer_halfcenter_pieclam.clamiter.prior.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inner Prod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BIGCLAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_triplets = [\n",
    "                    # ['feat_opt', 'n_iter', 2000],\n",
    "                    # ['feat_opt', 'lr', 0.00003],\n",
    "                    # ['prior_opt', 'n_iter', 1500],\n",
    "                    # ['prior_opt', 'lr', 0.0000005],\n",
    "                    # ['back_forth','n_back_forth', 50],\n",
    "                    # ['back_forth', 'first_func_in_fit', 'feat_opt']\n",
    "                ]\n",
    "\n",
    "\n",
    "trainer_halfcenter_bigclam= Trainer(\n",
    "                model_name='bigclam',\n",
    "                task='distance',\n",
    "                device=device,\n",
    "                config_triplets_to_change=config_triplets,\n",
    "                dataset=ds_sbm_halfcenter.clone()\n",
    ")\n",
    "\n",
    "losses_halfcenter_bigclam, logcut_halfcenter_bigclam, l2_halfcenter_bigclam = trainer_halfcenter_bigclam.train(\n",
    "    d = 0.2,\n",
    "    plot_every=-1,\n",
    "    init_feats=True,\n",
    "    init_type='small_gaus',\n",
    "    verbose=False,\n",
    "    verbose_in_funcs=False\n",
    ")\n",
    "\n",
    "del trainer_halfcenter_bigclam.data\n",
    "del trainer_halfcenter_bigclam.clamiter.prior.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PClam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SBM\n",
    "config_triplets = [\n",
    "                    ['feat_opt', 'n_iter', 2000],\n",
    "                    ['feat_opt', 'lr', 0.00005],\n",
    "                    ['prior_opt', 'n_iter', 1500],\n",
    "                    ['prior_opt', 'lr', 0.0000005],\n",
    "                    ['back_forth','n_back_forth', 30],\n",
    "                    # ['back_forth', 'first_func_in_fit', 'feat_opt']\n",
    "                ]\n",
    "\n",
    "\n",
    "trainer_halfcenter_pclam = Trainer(\n",
    "                model_name='pclam',\n",
    "                task='distance',\n",
    "                device=device,\n",
    "                config_triplets_to_change=config_triplets,\n",
    "                dataset=ds_sbm_halfcenter.clone()\n",
    ")\n",
    "# i want to optimize the trainer\n",
    "losses_halfcenter_pclam, logcut_halfcenter_pclam, l2_halfcenter_pclam = trainer_halfcenter_pclam.train(\n",
    "    d = 0.2,\n",
    "    plot_every=5,\n",
    "    init_feats=True,\n",
    "    init_type='small_gaus',\n",
    "    verbose=False,\n",
    "    verbose_in_funcs=False\n",
    ")\n",
    "\n",
    "del trainer_halfcenter_pclam.data\n",
    "del trainer_halfcenter_pclam.clamiter.prior.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogCut Convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find LL and LC Curve for Different d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.plotting import plot_distance_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Experiment: Find the best d. since the log cut distance is defined by the minimal d, we look to see which d gives the minimal value. In any case, the true log cut distance will always be smaller than what is calculated.'''\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "model_name='ieclam'\n",
    "ds_name = 'sbm3x3HalfDiag'\n",
    "\n",
    "\n",
    "\n",
    "ds = import_dataset(ds_name)\n",
    "\n",
    "\n",
    "# SBM\n",
    "config_triplets = [\n",
    "                    ['feat_opt', 'n_iter', 15000],\n",
    "                    # ['feat_opt', 'lr', 0.00005],\n",
    "                    # ['prior_opt', 'n_iter', 1500],\n",
    "                    # ['prior_opt', 'lr', 0.0000005],\n",
    "                    # ['back_forth','n_back_forth', 30],\n",
    "                    # ['back_forth', 'first_func_in_fit', 'feat_opt']\n",
    "                ]\n",
    "\n",
    "for d in [0.05, 0.01, 0.005]:\n",
    "    trainer = Trainer(\n",
    "                model_name=model_name,\n",
    "                task='distance',\n",
    "                device=device,\n",
    "                config_triplets_to_change=config_triplets,\n",
    "                dataset=ds.clone()\n",
    "    )\n",
    "    # i want to optimize the trainer\n",
    "    log_likelihoods, test_accs, val_accs = trainer.train(\n",
    "        d=d,\n",
    "        plot_every=-1,\n",
    "        init_feats=True,\n",
    "        init_type='small_gaus',\n",
    "        verbose=False,\n",
    "        acc_every=100,\n",
    "        verbose_in_funcs=False\n",
    "    )\n",
    "\n",
    "    log_likelihoods = np.array(log_likelihoods)/(ds.num_nodes**2)\n",
    "\n",
    "\n",
    "    dir_path = f'results/distance/find_d/{ds_name}/ieclam/d_{d}'\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "    torch.save(test_accs['log_cut'], dir_path + f'/logcuts')\n",
    "    torch.save(log_likelihoods, dir_path + f'/log_likelihoods')\n",
    "    torch.save(val_accs['l2'], dir_path + f'/l2s')\n",
    "    \n",
    "    del trainer.data\n",
    "    if trainer.clamiter.prior is not None:\n",
    "        del trainer.clamiter.prior.model\n",
    "    \n",
    "\n",
    "#todo: make one run for 50000 iteration and see if the log cut converges.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "piegam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
