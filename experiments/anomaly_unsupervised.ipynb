{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from the file \"sbm3x3_pclam_roc_0.210_auc_0.860\"\n",
    "import torch\n",
    "from torch_geometric.transforms import TwoHop\n",
    "\n",
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.insert(0, '..')\n",
    "\n",
    "from datasets.import_dataset import import_dataset\n",
    "from utils.plotting import *\n",
    "from trainer import Trainer\n",
    "import optimization_utils as ou\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using device:', device)\n",
    "cpu = torch.device(\"cpu\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%who"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run anomaly detection experiment with global params from hypers/hypers_link_prediction.yaml. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_names = ['pieclam']\n",
    "ds_names = ['elliptic']\n",
    "densifiable_ds = ['photo','reddit']\n",
    "num_reps = 2\n",
    "\n",
    "\n",
    "config_triplets = [['feat_opt', 'n_iter', 2200]]\n",
    "\n",
    "for model_name in model_names:    \n",
    "    for ds_name in ds_names:\n",
    "        #todo: make a data collection scheme\n",
    "        \n",
    "        ''' ds_to_use chooses whether to use the original dataset or the densified one. The trainer ds is the one that is used by the trainer that modifies it.'''\n",
    "        ds = import_dataset(ds_name)\n",
    "        ds_to_use = ds\n",
    "        \n",
    "        if ds_name in densifiable_ds:\n",
    "            fat_ds = TwoHop()(ds)\n",
    "            fat_ds.edge_attr = torch.ones(fat_ds.edge_index.shape[1]).bool()\n",
    "            ds_to_use = fat_ds\n",
    "    \n",
    "\n",
    "        losseses = []\n",
    "        acc_testses = []\n",
    "        acc_valses = []\n",
    "        try:\n",
    "            for i in range(num_reps):\n",
    "                trainer_anomaly = Trainer(\n",
    "                    model_name=model_name,\n",
    "                    device=device,\n",
    "                    dataset=ds_to_use,\n",
    "                    attr_opt=True,\n",
    "                    task='anomaly_unsupervised',\n",
    "                    use_global_config_base=True,  \n",
    "                    config_triplets_to_change=config_triplets          \n",
    "                )\n",
    "                \n",
    "                losses, acc_test, acc_val = trainer_anomaly.train(\n",
    "                    init_type='small_gaus',\n",
    "                    init_feats=True,\n",
    "                    acc_every=20,\n",
    "                    plot_every=-1,\n",
    "                    verbose=False,\n",
    "                    verbose_in_funcs=False\n",
    "                )\n",
    "                losseses.append(losses)\n",
    "                acc_testses.append(acc_test)\n",
    "                acc_valses.append(acc_val)\n",
    "                \n",
    "\n",
    "        except (Exception, KeyboardInterrupt) as e:\n",
    "            raise e\n",
    "        finally:\n",
    "            if trainer_anomaly is not None:\n",
    "                del trainer_anomaly\n",
    "            del ds\n",
    "            # del ds_to_use\n",
    "            if ds_name in densifiable_ds:\n",
    "                del fat_ds\n",
    "            torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scan ranges for hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'ieclam'\n",
    "ds_names = ['photo', 'reddit', 'elliptic']\n",
    "densifiable_ds = ['photo', 'reddit']\n",
    "n_reps = 1\n",
    "use_global_config_base = True\n",
    "\n",
    "#* perturb the global config\n",
    "deltas ={\n",
    "'clamiter_init': {'s_reg': 0.001,\n",
    "                  'l1_reg': 0.001,\n",
    "                  'dim_feat': 2},\n",
    "'feat_opt': {'n_iter': 200,\n",
    "            'lr': 0.0000005},\n",
    "'prior_opt': {'n_iter': 200,\n",
    "              'lr': 0.0000005,\n",
    "              'noise_amp': 0.01},\n",
    "'back_forth': {'sceduler_gamma' : 0.1}\n",
    "}\n",
    "\n",
    "range_triplets = ou.perturb_config('anomaly_unsupervised', \n",
    "                                   model_name, \n",
    "                                   deltas, \n",
    "                                   use_global_config=use_global_config_base)\n",
    "\n",
    "\n",
    "\n",
    "ou.multi_ds_anomaly(\n",
    "    model_name,\n",
    "    range_triplets,\n",
    "    n_reps,\n",
    "    use_global_config_base=use_global_config_base,\n",
    "    device=device,\n",
    "    ds_names=ds_names,\n",
    "    densifiable_ds=densifiable_ds,\n",
    "    attr_opt=True,\n",
    "    plot_every=-1\n",
    "    \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: GIT SHIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation Study: Densification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ABLATION STUDY WITHOUT DENSIFICATION\n",
    "\n",
    "model_names = ['pieclam']\n",
    "ds_names = ['photo', 'elliptic', 'reddit']\n",
    "\n",
    "\n",
    "final_accs = {'photo': {'vanilla_star':[],'prior':[],'prior_star':[]}, 'elliptic': {'vanilla_star':[],'prior':[],'prior_star':[]}, 'reddit': {'vanilla_star':[],'prior':[],'prior_star':[]}}\n",
    "\n",
    "for model_name in model_names:    \n",
    "    for ds_name in ds_names:\n",
    "        \n",
    "        ds = import_dataset(ds_name)\n",
    "        for _ in range(10):   \n",
    "            #! NOTICE: no densification!\n",
    "            ds_to_use = ds\n",
    "\n",
    "            \n",
    " \n",
    "            # config_triplets = [['feat_opt', 'n_iter', 20],\n",
    "            #                 ['prior_opt', 'n_iter', 20],]\n",
    "            config_triplets = []\n",
    "\n",
    "            trainer_anomaly = Trainer(\n",
    "                model_name=model_name,\n",
    "                device=device,\n",
    "                dataset=ds_to_use.clone(),\n",
    "                attr_opt=True,\n",
    "                task='anomaly_unsupervised',\n",
    "                use_global_configs_base=True,\n",
    "                config_triplets_to_change=config_triplets\n",
    "            )\n",
    "\n",
    "            losses, acc_test, acc_val = trainer_anomaly.train(\n",
    "                init_type='small_gaus',\n",
    "                init_feats=True,\n",
    "                acc_every=20,\n",
    "                plot_every=10000,\n",
    "                verbose=False,\n",
    "                verbose_in_funcs=False\n",
    "            )\n",
    "\n",
    "            final_accs[ds_name]['vanilla_star'].append(acc_test['vanilla_star'][-1])\n",
    "            final_accs[ds_name]['prior'].append(acc_test['prior'][-1])\n",
    "            final_accs[ds_name]['prior_star'].append(acc_test['prior_star'][-1])\n",
    "\n",
    "        if trainer_anomaly.clamiter.prior is not None:\n",
    "            del trainer_anomaly.clamiter.prior.model\n",
    "        del trainer_anomaly.data\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        del ds\n",
    "        del ds_to_use\n",
    "       \n",
    "        torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean and std for final accuracies.\n",
    "for key in final_accs:\n",
    "    print(key)\n",
    "    for key2 in final_accs[key]:\n",
    "        print(key2, np.mean(final_accs[key][key2]), np.std(final_accs[key][key2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anomaly detection with ieclam\n",
    "\n",
    "model_names = ['ieclam']\n",
    "ds_names = ['photo', 'elliptic', 'reddit']\n",
    "\n",
    "for model_name in model_names:    \n",
    "    for ds_name in ds_names:\n",
    "        \n",
    "        ds = import_dataset(ds_name)\n",
    "        if ds_name in ['reddit', 'photo', 'elliptic']:\n",
    "            fat_ds = TwoHop()(ds)\n",
    "            fat_ds.edge_attr = torch.ones(fat_ds.edge_index.shape[1]).bool()\n",
    "            ds_to_use = fat_ds\n",
    "        \n",
    "        # ds_to_use = ds\n",
    "        losseses = []\n",
    "        acc_testses = []\n",
    "        acc_valses = []\n",
    "        \n",
    "        '''change some of the configs manually e.g. \n",
    "        config_triplets = [['feat_opt', 'n_iter', 1000], ['prior_opt, 'lr', 0.0001], ...]'''\n",
    "        config_triplets = []\n",
    "\n",
    "        trainer_anomaly = Trainer(\n",
    "            model_name=model_name,\n",
    "            device=device,\n",
    "            dataset=ds_to_use.clone(),\n",
    "            attr_opt=True,\n",
    "            task='anomaly_unsupervised',\n",
    "            global_config_base=True,\n",
    "            config_triplets_to_change=config_triplets\n",
    "        )\n",
    "\n",
    "        losses, acc_test, acc_val = trainer_anomaly.train(\n",
    "            init_type='small_gaus',\n",
    "            init_feats=True,\n",
    "            acc_every=20,\n",
    "            plot_every=-1,\n",
    "            verbose=True,\n",
    "            verbose_in_funcs=False\n",
    "        )\n",
    "        losseses.append(losses)\n",
    "        acc_testses.append(acc_test)\n",
    "        acc_valses.append(acc_val)\n",
    "        \n",
    "        if trainer_anomaly.clamiter.prior is not None:\n",
    "            del trainer_anomaly.clamiter.prior.model\n",
    "        del trainer_anomaly.data\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    del ds\n",
    "    del ds_to_use\n",
    "    if ds_name in ['reddit', 'photo', 'elliptic']:\n",
    "        del fat_ds\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "piegam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
